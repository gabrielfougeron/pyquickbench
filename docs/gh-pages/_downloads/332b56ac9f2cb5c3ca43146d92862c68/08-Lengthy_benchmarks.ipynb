{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Time-consuming benchmarks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Benchmarking functions can be quite time consuming. This especially shows when the relative execution times of the different functions in the benchmark vary greatly. This is the case for the following general dense matrix-matrix multiplication benchmark:\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport numba as nb\n\nnumba_opt_dict = {\n    'nopython':True     ,\n    'cache':True        ,\n    'fastmath':True     ,\n    'nogil':True        ,\n}\n\nimport pyquickbench\n\ndef python(a, b, c):\n\n    for i in range(a.shape[0]):\n        for j in range(b.shape[1]):\n            for k in range(a.shape[1]):\n\n                c[i,j] += a[i,k]*b[k,j]\n                \ndef hybrid(a, b, c):\n\n    for i in range(a.shape[0]):\n        for j in range(b.shape[1]):\n\n            c[i,j] = np.dot(a[i,:],b[:,j])\n\ndef numpy(a, b, c):\n    np.matmul(a, b, out=c)\n    \nnumba_serial = nb.jit(python,**numba_opt_dict)\nnumba_serial.__name__ = \"numba_serial\"\n\n@nb.jit(parallel=True,**numba_opt_dict)\ndef numba_parallel(a, b, c):\n\n    for i in nb.prange(a.shape[0]):\n        for j in range(b.shape[1]):\n            for k in range(a.shape[1]):\n\n                c[i,j] += a[i,k]*b[k,j]\n\ndtypes_dict = {\n    \"float32\" : np.float32,\n    \"float64\" : np.float64,\n}\n\ndef setup_abc(n, real_dtype):\n    a = np.random.random((n,n)).astype(dtype=dtypes_dict[real_dtype])\n    b = np.random.random((n,n)).astype(dtype=dtypes_dict[real_dtype])\n    c = np.zeros((n,n),dtype=dtypes_dict[real_dtype])\n    return {'a':a, 'b':b, 'c':c}\n\nall_args = {\n    \"n\" : [(2 ** k) for k in range(8)]     ,\n    \"real_dtype\": [\"float32\", \"float64\"]   ,\n}\n\nall_funs = [\n    python          ,\n    hybrid          ,\n    numpy           ,\n    numba_serial    ,\n    numba_parallel  ,\n]\n\nn_repeat = 10\n\nall_values = pyquickbench.run_benchmark(\n    all_args                        ,\n    all_funs                        ,\n    setup = setup_abc               ,\n    n_repeat = n_repeat             ,\n    filename = timings_filename     ,\n) \n\nplot_intent = {\n    \"n\"         : \"points\"          ,\n    \"real_dtype\": \"curve_linestyle\" ,\n}\n\npyquickbench.plot_benchmark(\n    all_values                      ,\n    all_args                        ,\n    all_funs                        ,\n    plot_intent = plot_intent       ,\n    show = True                     ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On the above plot, we can see that each call to the ``python`` implementation needs arround 0.1 s to complete, whereas the ``numpy`` implementation (backed up by BLAS's dgemm) lasts less than a tenth of a milisecond. This is more than a 10 000 fold difference!\n\nEven worse: the previous benchmark only explores the pre-asymptotic behavior of the ``numpy`` implementation, but running the benchmark with higher values of ``\"n\"`` would be extremely time consuming.\n\nSince we know that typically, time measurements will be higher with higher values of ``\"n\"``, we can declare ``\"n\"`` as a ``MonotonicAxes``. Pyquickbench will skip benchmarks for high values of the parameters declared in ``MonotonicAxes`` as soon as a certain ``timeout`` is reached. This allows much larger values to be explored at a reasonnable CPU cost.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "basename = 'long_bench_2'\ntimings_filename = os.path.join(timings_folder, basename+'.npz')\n\nMonotonicAxes = [\"n\"]\ntimeout = 10.        # Floating point value in seconds\n\nall_args = {\n    \"n\" : [(2 ** k) for k in range(15)]    ,\n    \"real_dtype\": [\"float32\", \"float64\"]   ,\n}\n\nall_values = pyquickbench.run_benchmark(\n    all_args                        ,\n    all_funs                        ,\n    setup = setup_abc               ,\n    n_repeat = n_repeat             ,\n    timeout = timeout               ,\n    MonotonicAxes = MonotonicAxes   ,\n    filename = timings_filename     ,\n) \n\npyquickbench.plot_benchmark(\n    all_values                      ,\n    all_args                        ,\n    all_funs                        ,\n    plot_intent = plot_intent       ,\n    show = True                     ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plotting relative values shows that there can be a 100 000 fold difference between implementations!\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_to_val = {\n    \"real_dtype\": \"float32\"             ,\n    pyquickbench.fun_ax_name : \"numpy\"  ,\n}\n\npyquickbench.plot_benchmark(\n    all_values                      ,\n    all_args                        ,\n    all_funs                        ,\n    plot_intent = plot_intent       ,\n    show = True                     ,\n    title = \"Relative computational cost compared to numpy\" ,\n    ylabel = \"Relative time\"        ,\n    relative_to_val = relative_to_val,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also see that different methods need different sizes of input to reach their theoretically cubic asymptotic regime.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pyquickbench.plot_benchmark(\n    all_values                      ,\n    all_args                        ,\n    all_funs                        ,\n    plot_intent = plot_intent       ,\n    show = True                     ,\n    title = \"Computational cost growth order\"   ,\n    transform = \"pol_growth_order\"              ,\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}