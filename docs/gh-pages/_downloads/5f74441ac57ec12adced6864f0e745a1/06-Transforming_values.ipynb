{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting transformed values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's expand on the benchmark exposed in `sphx_glr__build_auto_examples_tutorial_05-Plotting_scalars.py`.\nThe benchmark consists in understanding the convergence behavior of the following ODE integrators provided by :mod:`scipy:scipy`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "method_names = [\n    \"RK45\"  ,  \n    \"RK23\"  ,  \n    \"DOP853\",  \n    \"Radau\" ,  \n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's focus on timings first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "timings_filename = os.path.join(bench_folder,basename_bench_filename+'_timings.npz') \ntimings_results = pyquickbench.run_benchmark(\n    all_nint                                    ,\n    bench                                       ,\n    filename = timings_filename                 ,\n)\n\npyquickbench.plot_benchmark(\n    timings_results                 ,\n    all_nint                        ,\n    bench                           ,\n    show = True                     ,\n    title = 'Computational cost'    , \n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check that the integrations algorithms provided by :mod:`scipy:scipy` scale linearly with respect to the number of integrations steps with the ``transform`` argument set to ``\"pol_growth_order\"``:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pyquickbench.plot_benchmark(\n    timings_results                             ,\n    all_nint                                    ,\n    bench                                       ,\n    logx_plot = True                            ,\n    title = \"Computational cost growth order\"   ,\n    transform = \"pol_growth_order\"              ,\n    show = True                                 ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since all the functions in the benchmark have the same asymptotic behavior, it makes sense to compare then against each other. Let's pick a reference method, for instance \"DOP853\" and plot all timings relative to this reference. This is achieved with the ``relative_to_val`` argument.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "relative_to_val = {pyquickbench.fun_ax_name: \"DOP853\"}\n\npyquickbench.plot_benchmark(\n    timings_results                         ,\n    all_nint                                ,\n    bench                                   ,\n    logx_plot = True                        ,\n    title = \"Relative computational cost\"   ,\n    relative_to_val = relative_to_val       ,\n    show = True                             ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's focus on accuracy measurements now.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_ylim = [1e-17, 1e1]\nscalar_filename = os.path.join(bench_folder,basename_bench_filename+'_error.npz')\nbench_results = pyquickbench.run_benchmark(\n    all_nint                                ,\n    bench                                   ,\n    mode = \"scalar_output\"                  ,\n    filename = scalar_filename               ,\n)\n\npyquickbench.plot_benchmark(\n    bench_results                           ,\n    all_nint                                ,\n    bench                                   ,\n    mode = \"scalar_output\"                  ,\n    plot_ylim = plot_ylim                   ,\n    title = 'Relative error on integrand'  ,\n    ylabel = \"Relative error\"               ,\n    show = True                             ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A natural question when assessing accuracy is to ask whether the measured convergence rates of the numerical methods match their theoretical convergence rates. This post-processing can be performed automatically by :func:`pyquickbench.run_benchmark` if the argument ``transform`` is set to ``\"pol_cvgence_order\"``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plot_ylim = [0, 10]\n\npyquickbench.plot_benchmark(\n    bench_results                           ,\n    all_nint                                ,\n    bench                                   ,\n    mode = \"scalar_output\"                  ,\n    plot_ylim = plot_ylim                   ,\n    ylabel = \"Measured convergence rate\"    ,\n    logx_plot = True                        ,\n    transform = \"pol_cvgence_order\"         ,\n    show = True                             ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The pre and post convergence behavior of the numerical algorithms really clutters the plots. In this case, a clearer plot is obtained if the argument ``clip_vals`` is set to ``True``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pyquickbench.plot_benchmark(\n    bench_results                           ,\n    all_nint                                ,\n    bench                                   ,\n    mode = \"scalar_output\"                  ,\n    plot_ylim = plot_ylim                   ,\n    ylabel = \"Measured convergence rate\"    ,\n    logx_plot = True                        ,\n    transform = \"pol_cvgence_order\"         ,\n    clip_vals = True                        ,\n    show = True                             ,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The measured values can now be compared to the theoretical convergence rates of the different methods. In order to plot your own data to the figure, you can handle the :class:`matplotlib:matplotlib.figure.Figure` and :class:`matplotlib:matplotlib.axes.Axes` objects yourself, And decouple the calls to :func:`pyquickbench.run_benchmark` and :func:`pyquickbench.plot_benchmark` as shown here.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "th_cvg_rate = {\n    \"RK45\"  : 5,  \n    \"RK23\"  : 3,  \n    \"DOP853\": 8,  \n    \"Radau\" : 5, \n}\n\nfig, ax = pyquickbench.plot_benchmark(\n    bench_results                           ,\n    all_nint                                ,\n    bench                                   ,\n    mode = \"scalar_output\"                  ,\n    show = False                            ,\n    plot_ylim = plot_ylim                   ,\n    ylabel = \"Measured convergence rate\"    ,\n    logx_plot = True                        ,\n    transform = \"pol_cvgence_order\"         ,\n    clip_vals = True                        ,\n)\n\nxlim = ax[0,0].get_xlim()\nfor name in bench:\n        \n    th_order = th_cvg_rate[name]\n    ax[0,0].plot(xlim, [th_order, th_order], linestyle='dotted')\n\nax[0,0].set_xlim(xlim)\nplt.tight_layout()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}