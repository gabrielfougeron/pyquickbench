
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "_build/auto_examples/tutorial/10-TimeTrains.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download__build_auto_examples_tutorial_10-TimeTrains.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr__build_auto_examples_tutorial_10-TimeTrains.py:


Time Trains
===========

.. GENERATED FROM PYTHON SOURCE LINES 7-8

As demonstrated in earlier posts in the tutorial, :mod:`pyquickbench` can be useful to measure the wall time of python functions. More often than not however, it can be useful to have a more precise idea of where cpu cycles are spent. This is the raison d'Ãªtre of :class:`pyquickbench.TimeTrain`. As shown in the following few lines, using a :class:`pyquickbench.TimeTrain` is extremely simple: simply call the :meth:`pyquickbench.TimeTrain.toc` method between snippets of code you want to time and :mod:`pyquickbench` takes care of the rest!

.. GENERATED FROM PYTHON SOURCE LINES 8-13

.. code-block:: Python



    import time
    import pyquickbench








.. GENERATED FROM PYTHON SOURCE LINES 45-66

.. code-block:: Python


    TT = pyquickbench.TimeTrain()

    time.sleep(0.01)
    TT.toc()

    time.sleep(0.02)
    TT.toc()

    time.sleep(0.03)
    TT.toc()

    time.sleep(0.04)
    TT.toc()

    time.sleep(0.01)
    TT.toc()    

    print(TT)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TimeTrain results:

    0.01008941 s at file 10-TimeTrains.py line 49
    0.02011453 s at file 10-TimeTrains.py line 52
    0.03014266 s at file 10-TimeTrains.py line 55
    0.04013044 s at file 10-TimeTrains.py line 58
    0.01008304 s at file 10-TimeTrains.py line 61

    Total: 0.11056009 s





.. GENERATED FROM PYTHON SOURCE LINES 67-68

Individual calls to :meth:`pyquickbench.TimeTrain.toc` can be named.

.. GENERATED FROM PYTHON SOURCE LINES 68-81

.. code-block:: Python


    TT = pyquickbench.TimeTrain()

    for i in range(3):
        time.sleep(0.01)
        TT.toc("repeated")

    for i in range(3):
        time.sleep(0.01)
        TT.toc(f"unique {i+1}")

    print(TT)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TimeTrain results:

    repeated: 0.01010623 s at file 10-TimeTrains.py line 73
    repeated: 0.01007090 s at file 10-TimeTrains.py line 73
    repeated: 0.01014701 s at file 10-TimeTrains.py line 73
    unique 1: 0.01009269 s at file 10-TimeTrains.py line 77
    unique 2: 0.01009717 s at file 10-TimeTrains.py line 77
    unique 3: 0.01009150 s at file 10-TimeTrains.py line 77

    Total: 0.06060550 s





.. GENERATED FROM PYTHON SOURCE LINES 82-83

Timing measurements relative to identical names can be reduced using any reduction method in :data:`pyquickbench.all_reductions`.

.. GENERATED FROM PYTHON SOURCE LINES 83-99

.. code-block:: Python


    TT = pyquickbench.TimeTrain(
        names_reduction = 'sum',
    )

    for i in range(3):
        time.sleep(0.01)
        TT.toc("repeated")

    for i in range(3):
        time.sleep(0.01)
        TT.toc(f"unique {i+1}")

    print(TT)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    /mnt/c/Users/gfo/Travail/Python/pyquickbench/pyquickbench/_time_train.py:87: UserWarning: include_locs and names_reduction were both enabled. Only the first location will be displayed for every name.
      warnings.warn("include_locs and names_reduction were both enabled. Only the first location will be displayed for every name.")
    TimeTrain results:

    repeated: 0.03032099 s at file 10-TimeTrains.py line 90
    unique 1: 0.01009115 s at file 10-TimeTrains.py line 94
    unique 2: 0.01009654 s at file 10-TimeTrains.py line 94
    unique 3: 0.01009300 s at file 10-TimeTrains.py line 94

    Total: 0.06060169 s





.. GENERATED FROM PYTHON SOURCE LINES 100-102

Reductions make locations ill-defined, which is why :class:`pyquickbench.TimeTrain` is issuing a warning. Another good reason to disable location recording is that the corresponding call to :func:`python:inspect.stack` can be non-negligible (around 0.01s on a generic laptop computer).
Displaying locations can be disabled like so:

.. GENERATED FROM PYTHON SOURCE LINES 102-119

.. code-block:: Python


    TT = pyquickbench.TimeTrain(
        names_reduction = 'sum',
        include_locs = False,
    )

    for i in range(3):
        time.sleep(0.01)
        TT.toc("repeated")

    for i in range(3):
        time.sleep(0.01)
        TT.toc(f"unique {i+1}")

    print(TT)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    TimeTrain results:

    repeated: 0.03042473 s
    unique 1: 0.01013447 s
    unique 2: 0.01015115 s
    unique 3: 0.01015635 s

    Total: 0.06086670 s





.. GENERATED FROM PYTHON SOURCE LINES 120-122

Let's revisit the benchmark in :ref:`sphx_glr__build_auto_examples_tutorial_09-Vector_output.py` and measure the execution time of different parts of the function ``uniform_quantiles`` using :class:`pyquickbench.TimeTrain`.


.. GENERATED FROM PYTHON SOURCE LINES 122-140

.. code-block:: Python


    def uniform_quantiles(n, m):
   
        TT = pyquickbench.TimeTrain(
            include_locs = False,
        )
    
        vec = np.random.random((n+1))
        TT.toc("Random sampling")
    
        vec.sort()
        TT.toc("Sorting")
    
        res = np.array([abs(vec[(n // m)*i]) for i in range(m+1)])
        TT.toc("Building result")

        return TT








.. GENERATED FROM PYTHON SOURCE LINES 141-146

This function can be divided up into three main parts:

* A random sampling phase, where data is generated. This part is expected to scale as :math:`\mathcal{O}(n)`.
* A sorting phase where the random vector is sorted in-place. This part is expected to scale as :math:`\mathcal{O}(n\log(n))`, and thus be dominant for large :math:`n`.
* A last phase where estimated quantiles are built and returned. This phase is expected to scale as :math:`\mathcal{O}(1)` and be negligible for large :math:`n`.

.. GENERATED FROM PYTHON SOURCE LINES 147-177

.. code-block:: Python


    
    m = 10
    uniform_decile = functools.partial(uniform_quantiles, m=m)
    uniform_decile.__name__ = "uniform_decile"
    
    all_funs = [
        uniform_decile   ,   
    ]

    n_bench = 20
    all_sizes = [m * 2**n for n in range(n_bench)]

    n_repeat = 100
    
    plot_intent = {
        pyquickbench.default_ax_name : "points"         ,   
        pyquickbench.out_ax_name : "curve_color"        ,   
    }

    pyquickbench.run_benchmark(
        all_sizes                       ,
        all_funs                        ,
        n_repeat = n_repeat             ,
        mode = "vector_output"          ,
        StopOnExcept = True             ,
        plot_intent = plot_intent       ,
        show = True                     ,
    ) 




.. image-sg:: /_build/auto_examples/tutorial/images/sphx_glr_10-TimeTrains_001.png
   :alt: 10 TimeTrains
   :srcset: /_build/auto_examples/tutorial/images/sphx_glr_10-TimeTrains_001.png
   :class: sphx-glr-single-img






.. _sphx_glr_download__build_auto_examples_tutorial_10-TimeTrains.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: 10-TimeTrains.ipynb <10-TimeTrains.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: 10-TimeTrains.py <10-TimeTrains.py>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
